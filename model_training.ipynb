{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Import Required Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:11:05.690346Z",
     "iopub.status.busy": "2024-01-06T09:11:05.690012Z",
     "iopub.status.idle": "2024-01-06T09:11:05.700881Z",
     "shell.execute_reply": "2024-01-06T09:11:05.698426Z",
     "shell.execute_reply.started": "2024-01-06T09:11:05.690318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from IPython.display import Image as IPImage\n",
    "import pandas as pd             # Pandas\n",
    "import numpy as np              # NumPy\n",
    "import matplotlib.pyplot as plt # Matplotlib\n",
    "import seaborn as sns           # Seaborn\n",
    "from PIL import Image           # Pillow\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Keras\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout\n",
    "from keras import models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, Adamax\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications import DenseNet121\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directory Names Containing Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:02.267674Z",
     "iopub.status.busy": "2024-01-06T09:08:02.266695Z",
     "iopub.status.idle": "2024-01-06T09:08:02.313371Z",
     "shell.execute_reply": "2024-01-06T09:08:02.311921Z",
     "shell.execute_reply.started": "2024-01-06T09:08:02.267626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the path to the directory containing the images for training\n",
    "train_data = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Create a Pandas DataFrame with a single column\n",
    "# The column is populated with the list of file/directory names in the 'train_data' directory\n",
    "pd.DataFrame(\n",
    "    os.listdir(train_data),\n",
    "    columns=['File Name']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directory Paths Containing Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:05.055958Z",
     "iopub.status.busy": "2024-01-06T09:08:05.055613Z",
     "iopub.status.idle": "2024-01-06T09:08:05.446744Z",
     "shell.execute_reply": "2024-01-06T09:08:05.445313Z",
     "shell.execute_reply.started": "2024-01-06T09:08:05.055932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get a list of the file paths in the 'train_data' directory\n",
    "train_files = [i for i in glob.glob(train_data + \"/*/*\")]\n",
    "\n",
    "# Randomly shuffle the list of file paths\n",
    "np.random.shuffle(train_files)\n",
    "\n",
    "# Extract labels from the directory names of each file path\n",
    "labels = [os.path.dirname(i).split(\"/\")[-1] for i in train_files]\n",
    "\n",
    "# Combine file paths & its corresponding labels into a list of tuples\n",
    "data = zip(train_files, labels)\n",
    "\n",
    "# Create a Pandas DataFrame with 2 columns\n",
    "# \"Path\" column contains file paths, & \"Label\" column contains corresponding labels\n",
    "training_data = pd.DataFrame(data, columns=[\"Path\", \"Label\"])\n",
    "\n",
    "# Display the contents of the DataFrame\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:13.284156Z",
     "iopub.status.busy": "2024-01-06T09:08:13.283424Z",
     "iopub.status.idle": "2024-01-06T09:08:13.462472Z",
     "shell.execute_reply": "2024-01-06T09:08:13.461404Z",
     "shell.execute_reply.started": "2024-01-06T09:08:13.284122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a countplot() using Seaborn, where x-axis represents the \"Label\" column of the training_data DataFrame\n",
    "ax = sns.countplot(x=training_data[\"Label\"])\n",
    "\n",
    "# Display count inside each bar as integers\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add a title with the total count of files\n",
    "plt.title(f'Total Files: {len(training_data)}', pad=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Collect Data Paths & Labels from Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:19.227399Z",
     "iopub.status.busy": "2024-01-06T09:08:19.226789Z",
     "iopub.status.idle": "2024-01-06T09:08:19.239952Z",
     "shell.execute_reply": "2024-01-06T09:08:19.238439Z",
     "shell.execute_reply.started": "2024-01-06T09:08:19.227368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_paths = []\n",
    "labels = []\n",
    "\n",
    "main_dirs = os.listdir(train_data)\n",
    "for folder_name in main_dirs:\n",
    "    folder_path = os.path.join(train_data, folder_name)\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data_paths.append(file_path)\n",
    "        labels.append(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:21.824087Z",
     "iopub.status.busy": "2024-01-06T09:08:21.823619Z",
     "iopub.status.idle": "2024-01-06T09:08:23.052832Z",
     "shell.execute_reply": "2024-01-06T09:08:23.051850Z",
     "shell.execute_reply.started": "2024-01-06T09:08:21.824046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Define the target image size for preprocessing\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Specify the number of color channels in the images (3 for RGB)\n",
    "num_channels = 3\n",
    "\n",
    "# Create the image shape tuple based on the specified size and channels\n",
    "image_shape = (image_size[0], image_size[1], num_channels)\n",
    "\n",
    "# Create a Pandas Series containing file paths with the name 'Path'\n",
    "data_dirs = pd.Series(data_paths, name='Path')\n",
    "\n",
    "# Create a Pandas Series containing corresponding labels with the name 'Label'\n",
    "classes = pd.Series(labels, name='Label')\n",
    "\n",
    "def preprocess_image(img):\n",
    "    return img\n",
    "\n",
    "# Split the data into training and validation-test sets\n",
    "train_df, val_test_df = train_test_split(\n",
    "    training_data, \n",
    "    train_size=0.8, \n",
    "    shuffle=True, \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Further split the validation-test set into validation and test sets\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df, \n",
    "    train_size=0.5, \n",
    "    shuffle=True, \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# ImageDataGenerator configuration\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image, \n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "# Convert the 'Label' column to string type\n",
    "train_df['Label'] = train_df['Label'].astype(str)\n",
    "val_df['Label'] = val_df['Label'].astype(str)\n",
    "test_df['Label'] = test_df['Label'].astype(str)\n",
    "\n",
    "# Create generators for training, validation, and testing\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    x_col='Path', \n",
    "    y_col='Label',\n",
    "    target_size=image_size, \n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb', \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    val_df, \n",
    "    x_col='Path', \n",
    "    y_col='Label',\n",
    "    target_size=image_size, \n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb', \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    x_col='Path', \n",
    "    y_col='Label',\n",
    "    target_size=image_size, \n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb', \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Class Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:33.912034Z",
     "iopub.status.busy": "2024-01-06T09:08:33.911678Z",
     "iopub.status.idle": "2024-01-06T09:08:33.919417Z",
     "shell.execute_reply": "2024-01-06T09:08:33.918248Z",
     "shell.execute_reply.started": "2024-01-06T09:08:33.912006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the class indices (mapping of the class names to numerical indices) from the training generator\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Display the keys (class names) from the class_indices dictionary\n",
    "class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:35.845917Z",
     "iopub.status.busy": "2024-01-06T09:08:35.845071Z",
     "iopub.status.idle": "2024-01-06T09:08:35.853369Z",
     "shell.execute_reply": "2024-01-06T09:08:35.851980Z",
     "shell.execute_reply.started": "2024-01-06T09:08:35.845888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store class labels\n",
    "labels = []\n",
    "\n",
    "# Iterate through the keys (class names) in the class_indices dictionary\n",
    "for key in class_indices.keys():\n",
    "    labels.append(key)  # Append each class name to the labels list\n",
    "\n",
    "# Calculate the total no. of unique labels\n",
    "total_labels = len(labels)\n",
    "\n",
    "# Print the list of class labels and the total no. of unique labels\n",
    "print(\"Labels: \", labels)\n",
    "print(\"\\nTotal no. of unique labels:\", total_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize a Subset of Images from the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:38.577117Z",
     "iopub.status.busy": "2024-01-06T09:08:38.576655Z",
     "iopub.status.idle": "2024-01-06T09:08:39.294017Z",
     "shell.execute_reply": "2024-01-06T09:08:39.291781Z",
     "shell.execute_reply.started": "2024-01-06T09:08:38.577083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the number of rows and columns for the subplot grid\n",
    "no_of_rows = 2\n",
    "no_of_columns = 4\n",
    "\n",
    "# Create a subplot grid with the specified number of rows and columns\n",
    "fig, axes = plt.subplots(no_of_rows, no_of_columns, figsize=(12, 8))\n",
    "\n",
    "# Iterate through the rows\n",
    "for i in range(no_of_rows):\n",
    "    # Iterate through the columns\n",
    "    for j in range(no_of_columns):\n",
    "        # Calculate the index for accessing the data\n",
    "        index = i * no_of_columns + j\n",
    "\n",
    "        # Check if the index is within the bounds of the data\n",
    "        if index < len(training_data):\n",
    "\n",
    "            # Open the image using the PIL library\n",
    "            im = Image.open(training_data.iloc[index]['Path'])\n",
    "\n",
    "            # Convert the PIL image to a NumPy array\n",
    "            img = np.array(im)\n",
    "\n",
    "            # Print the shape of the image array\n",
    "            print(img.shape)\n",
    "\n",
    "            # Display the image on the subplot at position (i, j)\n",
    "            axes[i, j].imshow(img)\n",
    "\n",
    "            # Turn off axis labels for better visualization\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "            # Get the label for the current image and display it as text\n",
    "            label = training_data.iloc[index]['Label']\n",
    "            axes[i, j].text(0.5, -0.1, label, ha='center', transform=axes[i, j].transAxes)\n",
    "\n",
    "# Show the entire subplot grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:08:46.657260Z",
     "iopub.status.busy": "2024-01-06T09:08:46.656397Z",
     "iopub.status.idle": "2024-01-06T09:08:53.183975Z",
     "shell.execute_reply": "2024-01-06T09:08:53.182914Z",
     "shell.execute_reply.started": "2024-01-06T09:08:46.657225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load DenseNet-121 with pre-trained weights\n",
    "base_model = DenseNet121(\n",
    "    weights='/kaggle/input/densenet121-weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    include_top=False, \n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the pre-trained DenseNet-121 base model\n",
    "model.add(base_model)\n",
    "\n",
    "# Flatten the output of the base model\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers with dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Additional layers for classification\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Display the summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Neural Network Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:11:14.620899Z",
     "iopub.status.busy": "2024-01-06T09:11:14.620404Z",
     "iopub.status.idle": "2024-01-06T09:11:14.715457Z",
     "shell.execute_reply": "2024-01-06T09:11:14.713822Z",
     "shell.execute_reply.started": "2024-01-06T09:11:14.620857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Specify the file path for saving the visualization image\n",
    "model_visualization_path = \"/kaggle/working/nn_architecture.png\"\n",
    "\n",
    "# Plot the model and save the visualization image\n",
    "plot_model(model, to_file=model_visualization_path, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the visualization image\n",
    "IPImage(filename=model_visualization_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Model Checkpoint Callback to Save Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:11:30.598875Z",
     "iopub.status.busy": "2024-01-06T09:11:30.598392Z",
     "iopub.status.idle": "2024-01-06T09:11:30.604013Z",
     "shell.execute_reply": "2024-01-06T09:11:30.603054Z",
     "shell.execute_reply.started": "2024-01-06T09:11:30.598836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the path to save the best model checkpoint\n",
    "checkpoint_path = \"/kaggle/working/model.h5\"\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "# This callback saves the model when validation accuracy improves\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,     # Save only the best model\n",
    "    mode='max',              # Save based on the maximum validation accuracy\n",
    "    verbose=1                # Display progress information\n",
    ")                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:11:33.567611Z",
     "iopub.status.busy": "2024-01-06T09:11:33.567130Z",
     "iopub.status.idle": "2024-01-06T09:11:33.599754Z",
     "shell.execute_reply": "2024-01-06T09:11:33.598329Z",
     "shell.execute_reply.started": "2024-01-06T09:11:33.567577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Categorical crossentropy loss for multi-class classification\n",
    "    metrics=['accuracy']              # Monitor accuracy during training\n",
    ")              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIII. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:11:46.551326Z",
     "iopub.status.busy": "2024-01-06T09:11:46.550855Z",
     "iopub.status.idle": "2024-01-06T09:35:17.703223Z",
     "shell.execute_reply": "2024-01-06T09:35:17.701968Z",
     "shell.execute_reply.started": "2024-01-06T09:11:46.551280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model using the fit() method\n",
    "history = model.fit(\n",
    "    train_generator,                                   # Training data generator\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Number of steps per epoch\n",
    "    epochs=10,                                         # Number of training epochs\n",
    "    validation_data=valid_generator,                   # Validation data generator\n",
    "    validation_steps=valid_generator.samples // valid_generator.batch_size,  # Number of validation steps\n",
    "    callbacks=[checkpoint]                             # List of callbacks, including the ModelCheckpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Training History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:35:26.881515Z",
     "iopub.status.busy": "2024-01-06T09:35:26.880719Z",
     "iopub.status.idle": "2024-01-06T09:35:26.897121Z",
     "shell.execute_reply": "2024-01-06T09:35:26.896280Z",
     "shell.execute_reply.started": "2024-01-06T09:35:26.881483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame containing the training history (metrics) of the model\n",
    "train_history = pd.DataFrame(history.history)\n",
    "\n",
    "# Add a new column 'Epoch' with values from 1 to the number of epochs\n",
    "train_history['Epoch'] = range(1, len(train_history) + 1)\n",
    "\n",
    "# Reorder columns for clarity\n",
    "train_history = train_history[['Epoch', 'loss', 'accuracy', 'val_loss', 'val_accuracy']]\n",
    "\n",
    "# Display the DataFrame\n",
    "train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX. Evaluate Model (Train & Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:35:31.527960Z",
     "iopub.status.busy": "2024-01-06T09:35:31.527264Z",
     "iopub.status.idle": "2024-01-06T09:37:14.323962Z",
     "shell.execute_reply": "2024-01-06T09:37:14.320926Z",
     "shell.execute_reply.started": "2024-01-06T09:35:31.527926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the train set\n",
    "train_loss, train_accuracy = model.evaluate(train_generator, steps=train_generator.samples // train_generator.batch_size)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(valid_generator, steps=valid_generator.samples // valid_generator.batch_size)\n",
    "\n",
    "# Convert accuracy to percentage\n",
    "train_accuracy_percentage = train_accuracy * 100\n",
    "val_accuracy_percentage = val_accuracy * 100\n",
    "\n",
    "# Create a Pandas DataFrame to display the results\n",
    "evaluation_results = pd.DataFrame({\n",
    "    'Set': ['Train', 'Validation'],\n",
    "    'Loss': [train_loss, val_loss],\n",
    "    'Accuracy': [f'{train_accuracy_percentage:.2f}%', f'{val_accuracy_percentage:.2f}%']\n",
    "})\n",
    "\n",
    "# Display the evaluation results DataFrame\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Loss & Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T09:40:44.707226Z",
     "iopub.status.busy": "2024-01-06T09:40:44.706670Z",
     "iopub.status.idle": "2024-01-06T09:40:45.190153Z",
     "shell.execute_reply": "2024-01-06T09:40:45.188604Z",
     "shell.execute_reply.started": "2024-01-06T09:40:44.707185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_history['loss'], label='Training Loss')\n",
    "plt.plot(train_history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(train_history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1209633,
     "sourceId": 2021025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4256535,
     "sourceId": 7332376,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
